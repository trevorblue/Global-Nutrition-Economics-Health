{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1bf0b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0828305",
   "metadata": {},
   "source": [
    "### What this prototype does\n",
    "\n",
    "* Classical ML (6 models) → regression predictions + metrics + timings\n",
    "\n",
    "* Deep Learning (Keras) → regression predictions + metrics + learning curves\n",
    "\n",
    "* Quantum Regression (VQR) on a small subset (for speed) → continuous predictions comparable to the other models, with graceful fallback if Qiskit ML isn’t available.\n",
    "\n",
    "## Assumptions\n",
    "• You already have df in memory with these numeric columns:\n",
    "[\"Calories_per_person\",\"Fat_grams_per_person\",\"Protein_grams_per_person\",\"GDP_per_capita\",\"Obesity_rate_percent\",\"Undernourishment_rate_percent\",\"Life_expectancy\"]\n",
    "• You’ve imported the usual stack: pandas, numpy, matplotlib, sklearn, xgboost, tensorflow/keras.\n",
    "• If Qiskit ML isn’t installed, the Quantum block will skip and tell you exactly why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24386c7",
   "metadata": {},
   "source": [
    "### 3. FEATURE ENGINEERING, SPLIT & SCALING  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "195a80bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 5) FEATURE ENGINEERING, SPLIT & SCALING  (Regression target: Life_expectancy)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Goal: Build one consistent pipeline where ALL models (classical, deep learning, quantum)\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#       predict the SAME continuous target (life expectancy). This lets us compare apples-to-apples.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\__init__.py:61\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     63\u001b[39m     ArrowDtype,\n\u001b[32m     64\u001b[39m     Int8Dtype,\n\u001b[32m     65\u001b[39m     Int16Dtype,\n\u001b[32m     66\u001b[39m     Int32Dtype,\n\u001b[32m     67\u001b[39m     Int64Dtype,\n\u001b[32m     68\u001b[39m     UInt8Dtype,\n\u001b[32m     69\u001b[39m     UInt16Dtype,\n\u001b[32m     70\u001b[39m     UInt32Dtype,\n\u001b[32m     71\u001b[39m     UInt64Dtype,\n\u001b[32m     72\u001b[39m     Float32Dtype,\n\u001b[32m     73\u001b[39m     Float64Dtype,\n\u001b[32m     74\u001b[39m     CategoricalDtype,\n\u001b[32m     75\u001b[39m     PeriodDtype,\n\u001b[32m     76\u001b[39m     IntervalDtype,\n\u001b[32m     77\u001b[39m     DatetimeTZDtype,\n\u001b[32m     78\u001b[39m     StringDtype,\n\u001b[32m     79\u001b[39m     BooleanDtype,\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     81\u001b[39m     NA,\n\u001b[32m     82\u001b[39m     isna,\n\u001b[32m     83\u001b[39m     isnull,\n\u001b[32m     84\u001b[39m     notna,\n\u001b[32m     85\u001b[39m     notnull,\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     87\u001b[39m     Index,\n\u001b[32m     88\u001b[39m     CategoricalIndex,\n\u001b[32m     89\u001b[39m     RangeIndex,\n\u001b[32m     90\u001b[39m     MultiIndex,\n\u001b[32m     91\u001b[39m     IntervalIndex,\n\u001b[32m     92\u001b[39m     TimedeltaIndex,\n\u001b[32m     93\u001b[39m     DatetimeIndex,\n\u001b[32m     94\u001b[39m     PeriodIndex,\n\u001b[32m     95\u001b[39m     IndexSlice,\n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     97\u001b[39m     NaT,\n\u001b[32m     98\u001b[39m     Period,\n\u001b[32m     99\u001b[39m     period_range,\n\u001b[32m    100\u001b[39m     Timedelta,\n\u001b[32m    101\u001b[39m     timedelta_range,\n\u001b[32m    102\u001b[39m     Timestamp,\n\u001b[32m    103\u001b[39m     date_range,\n\u001b[32m    104\u001b[39m     bdate_range,\n\u001b[32m    105\u001b[39m     Interval,\n\u001b[32m    106\u001b[39m     interval_range,\n\u001b[32m    107\u001b[39m     DateOffset,\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m    109\u001b[39m     to_numeric,\n\u001b[32m    110\u001b[39m     to_datetime,\n\u001b[32m    111\u001b[39m     to_timedelta,\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m    113\u001b[39m     Flags,\n\u001b[32m    114\u001b[39m     Grouper,\n\u001b[32m    115\u001b[39m     factorize,\n\u001b[32m    116\u001b[39m     unique,\n\u001b[32m    117\u001b[39m     value_counts,\n\u001b[32m    118\u001b[39m     NamedAgg,\n\u001b[32m    119\u001b[39m     array,\n\u001b[32m    120\u001b[39m     Categorical,\n\u001b[32m    121\u001b[39m     set_eng_float_format,\n\u001b[32m    122\u001b[39m     Series,\n\u001b[32m    123\u001b[39m     DataFrame,\n\u001b[32m    124\u001b[39m )\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\api.py:28\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     isna,\n\u001b[32m     18\u001b[39m     isnull,\n\u001b[32m     19\u001b[39m     notna,\n\u001b[32m     20\u001b[39m     notnull,\n\u001b[32m     21\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     24\u001b[39m     factorize,\n\u001b[32m     25\u001b[39m     unique,\n\u001b[32m     26\u001b[39m     value_counts,\n\u001b[32m     27\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Categorical\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mboolean\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BooleanDtype\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfloating\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     31\u001b[39m     Float32Dtype,\n\u001b[32m     32\u001b[39m     Float64Dtype,\n\u001b[32m     33\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\arrays\\__init__.py:8\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     ExtensionArray,\n\u001b[32m      4\u001b[39m     ExtensionOpsMixin,\n\u001b[32m      5\u001b[39m     ExtensionScalarOpsMixin,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mboolean\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BooleanArray\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcategorical\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Categorical\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatetimes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatetimeArray\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfloating\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FloatingArray\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\arrays\\categorical.py:66\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     57\u001b[39m     is_valid_na_for_dtype,\n\u001b[32m     58\u001b[39m     isna,\n\u001b[32m     59\u001b[39m )\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     algorithms,\n\u001b[32m     63\u001b[39m     arraylike,\n\u001b[32m     64\u001b[39m     ops,\n\u001b[32m     65\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccessor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     67\u001b[39m     PandasDelegate,\n\u001b[32m     68\u001b[39m     delegate_names,\n\u001b[32m     69\u001b[39m )\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     71\u001b[39m     factorize,\n\u001b[32m     72\u001b[39m     take_nd,\n\u001b[32m     73\u001b[39m )\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_mixins\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     75\u001b[39m     NDArrayBackedExtensionArray,\n\u001b[32m     76\u001b[39m     ravel_compat,\n\u001b[32m     77\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1022\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1118\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1217\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5) FEATURE ENGINEERING, SPLIT & SCALING  (Regression target: Life_expectancy)\n",
    "# ============================================================\n",
    "# Goal: Build one consistent pipeline where ALL models (classical, deep learning, quantum)\n",
    "#       predict the SAME continuous target (life expectancy). This lets us compare apples-to-apples.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# -----------------------------\n",
    "# Select features (X) and target (y)\n",
    "# -----------------------------\n",
    "# You can swap the target to 'Obesity_rate_percent' or 'Undernourishment_rate_percent'\n",
    "# to repeat the entire comparison for those outcomes.\n",
    "X = df[[\n",
    "    \"Calories_per_person\",\n",
    "    \"Fat_grams_per_person\",\n",
    "    \"Protein_grams_per_person\",\n",
    "    \"GDP_per_capita\",\n",
    "    \"Obesity_rate_percent\",\n",
    "    \"Undernourishment_rate_percent\"\n",
    "]].copy()\n",
    "\n",
    "y = df[\"Life_expectancy\"].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Train/validation/test split\n",
    "# -----------------------------\n",
    "# Split into train and test so we can estimate out-of-sample generalization.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Scale features\n",
    "# -----------------------------\n",
    "# Scaling is crucial for models sensitive to feature magnitude (linear/NN/QML).\n",
    "# Tree models don't need scaling, but for fairness we'll feed the same scaled arrays.\n",
    "x_scaler = StandardScaler()\n",
    "X_train_scaled = x_scaler.fit_transform(X_train)\n",
    "X_test_scaled  = x_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548f775",
   "metadata": {},
   "source": [
    "### 4. CLASSICAL MACHINE LEARNING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6) CLASSICAL MACHINE LEARNING MODELS (Regression)\n",
    "# ============================================================\n",
    "# We train several regressors, time them, and report MSE/RMSE/MAE/R².\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Optional: XGBoost if installed\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    xgb_ok = True\n",
    "except Exception:\n",
    "    xgb_ok = False\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(random_state=42),\n",
    "    \"Lasso Regression\": Lasso(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=300, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "if xgb_ok:\n",
    "    models[\"XGBoost\"] = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "results = []   # to collect metrics/timings\n",
    "pred_store = {}  # to keep predictions per model for quick comparison\n",
    "\n",
    "for name, model in models.items():\n",
    "    t0 = time.perf_counter()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    fit_time = time.perf_counter() - t0\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    preds = model.predict(X_test_scaled)\n",
    "    pred_time = time.perf_counter() - t1\n",
    "\n",
    "    mse  = mean_squared_error(y_test, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae  = mean_absolute_error(y_test, preds)\n",
    "    r2   = r2_score(y_test, preds)\n",
    "    results.append([name, \"Classical\", mse, rmse, mae, r2, fit_time, pred_time])\n",
    "    pred_store[name] = preds\n",
    "\n",
    "# Pretty print classical metrics\n",
    "res_df = pd.DataFrame(results, columns=[\"Model\",\"Family\",\"MSE\",\"RMSE\",\"MAE\",\"R2\",\"Fit_s\",\"Pred_s\"])\n",
    "print(\"\\n=== Classical ML Results ===\")\n",
    "print(res_df.sort_values(\"R2\", ascending=False).to_string(index=False))\n",
    "\n",
    "# Show a few prediction vs actual pairs for the current best classical model\n",
    "best_clf = res_df.sort_values(\"R2\", ascending=False).iloc[0][\"Model\"]\n",
    "print(f\"\\nSample predictions (Classical - {best_clf}) vs actual (first 10 rows):\")\n",
    "for i in range(10):\n",
    "    print(f\"Pred: {pred_store[best_clf][i]:6.2f} | Actual: {y_test.iloc[i]:6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd736c0",
   "metadata": {},
   "source": [
    "### 5. Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c32907",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 7) DEEP LEARNING REGRESSION (Keras)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# A compact fully connected network with dropout + early stopping.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tensorflow\\__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7) DEEP LEARNING REGRESSION (Keras)\n",
    "# ============================================================\n",
    "# A compact fully connected network with dropout + early stopping.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "dl_model = Sequential([\n",
    "    # input_shape = number of features in X\n",
    "    Dense(128, activation=\"relu\", input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.25),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.25),\n",
    "    Dense(1)  # 1 continuous output = regression\n",
    "])\n",
    "\n",
    "dl_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Early stopping to prevent overfitting; restore the best weights on val loss\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=20, restore_best_weights=True, verbose=0\n",
    ")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "history = dl_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,  # 20% of TRAIN used as validation (not touching test!)\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "dl_fit_time = time.perf_counter() - t0\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "dl_preds = dl_model.predict(X_test_scaled, verbose=0).reshape(-1)\n",
    "dl_pred_time = time.perf_counter() - t1\n",
    "\n",
    "dl_mse  = mean_squared_error(y_test, dl_preds)\n",
    "dl_rmse = np.sqrt(dl_mse)\n",
    "dl_mae  = mean_absolute_error(y_test, dl_preds)\n",
    "dl_r2   = r2_score(y_test, dl_preds)\n",
    "\n",
    "res_df = pd.concat([\n",
    "    res_df,\n",
    "    pd.DataFrame([[\"Neural Net (Keras)\",\"Deep Learning\", dl_mse, dl_rmse, dl_mae, dl_r2, dl_fit_time, dl_pred_time]],\n",
    "                 columns=res_df.columns)\n",
    "], ignore_index=True)\n",
    "\n",
    "print(\"\\n=== Deep Learning Result ===\")\n",
    "print(res_df[res_df[\"Model\"]==\"Neural Net (Keras)\"].to_string(index=False))\n",
    "\n",
    "# Show some NN predictions vs actual\n",
    "print(\"\\nSample predictions (Deep Learning) vs actual (first 10 rows):\")\n",
    "for i in range(10):\n",
    "    print(f\"Pred: {dl_preds[i]:6.2f} | Actual: {y_test.iloc[i]:6.2f}\")\n",
    "\n",
    "# Plot training curves so you can visually inspect over/underfitting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train MSE\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val MSE\")\n",
    "plt.title(\"Neural Network Training Curve (loss=MSE)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab39dd56",
   "metadata": {},
   "source": [
    "### 6. Quantum ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3dbd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8) QUANTUM MACHINE LEARNING (QML) — Variational Quantum REGRESSOR (VQR)\n",
    "# ============================================================\n",
    "# IMPORTANT:\n",
    "# • Quantum training is expensive; we use a SMALL subset for a meaningful demo.\n",
    "# • We STANDARDIZE the target for the quantum model to help the optimizer,\n",
    "#   then inverse-transform predictions back to the original scale.\n",
    "# • If qiskit-machine-learning (with VQR) is not installed, we skip gracefully.\n",
    "\n",
    "qml_available = True\n",
    "try:\n",
    "    # Backends & utilities\n",
    "    from qiskit import Aer\n",
    "    from qiskit.circuit.library import TwoLocal, ZZFeatureMap\n",
    "    from qiskit.utils import QuantumInstance\n",
    "    # VQR used to be in different namespaces depending on version\n",
    "    try:\n",
    "        from qiskit_machine_learning.algorithms.regressors import VQR\n",
    "    except Exception:\n",
    "        from qiskit_machine_learning.algorithms import VQR\n",
    "    # Optimizers\n",
    "    from qiskit.algorithms.optimizers import COBYLA\n",
    "except Exception as e:\n",
    "    qml_available = False\n",
    "    qml_import_error = str(e)\n",
    "\n",
    "if qml_available:\n",
    "    # -----------------------------\n",
    "    # Subsample for speed (tune N down if slow; up if you want more capacity)\n",
    "    # -----------------------------\n",
    "    Ntrain_q = min(128, X_train_scaled.shape[0])\n",
    "    Ntest_q  = min(64,  X_test_scaled.shape[0])\n",
    "\n",
    "    X_q_train = X_train_scaled[:Ntrain_q]\n",
    "    X_q_test  = X_test_scaled[:Ntest_q]\n",
    "\n",
    "    # Scale target specifically for quantum regressor (helps the optimizer landscape).\n",
    "    y_q_scaler = StandardScaler()\n",
    "    y_q_train  = y_q_scaler.fit_transform(y_train.values[:Ntrain_q].reshape(-1,1)).ravel()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Build the quantum model\n",
    "    # -----------------------------\n",
    "    # num_qubits must match number of features. We have 6 features → 6 qubits.\n",
    "    num_qubits = X_q_train.shape[1]\n",
    "\n",
    "    # Feature map: encodes classical features into a quantum state\n",
    "    # ZZFeatureMap introduces entanglement and non-linearity; reps controls depth.\n",
    "    feature_map = ZZFeatureMap(num_qubits=num_qubits, reps=1)\n",
    "\n",
    "    # Ansatz (variational circuit): learnable parameters adjusted by optimizer\n",
    "    ansatz = TwoLocal(\n",
    "        num_qubits=num_qubits,\n",
    "        rotation_blocks=\"ry\",\n",
    "        entanglement_blocks=\"cz\",\n",
    "        entanglement=\"linear\",\n",
    "        reps=2\n",
    "    )\n",
    "\n",
    "    # Quantum simulator backend; statevector is usually faster for small circuits\n",
    "    backend = Aer.get_backend(\"aer_simulator_statevector\")\n",
    "    qi = QuantumInstance(backend=backend, shots=None)  # shots=None uses exact statevector exp.\n",
    "\n",
    "    # Classical optimizer for the variational parameters\n",
    "    optimizer = COBYLA(maxiter=200, tol=1e-3)\n",
    "\n",
    "    # Variational Quantum Regressor\n",
    "    vqr = VQR(\n",
    "        feature_map=feature_map,\n",
    "        ansatz=ansatz,\n",
    "        optimizer=optimizer,\n",
    "        quantum_instance=qi\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Train & predict with timing\n",
    "    # -----------------------------\n",
    "    t0 = time.perf_counter()\n",
    "    vqr.fit(X_q_train, y_q_train)\n",
    "    q_fit_time = time.perf_counter() - t0\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    q_pred_scaled = vqr.predict(X_q_test).reshape(-1)\n",
    "    q_pred_time = time.perf_counter() - t1\n",
    "\n",
    "    # Inverse-transform back to original life-expectancy scale\n",
    "    q_preds = y_q_scaler.inverse_transform(q_pred_scaled.reshape(-1,1)).ravel()\n",
    "\n",
    "    # For proper comparable metrics, take the matching y_test slice\n",
    "    y_test_qslice = y_test.iloc[:Ntest_q].values\n",
    "\n",
    "    q_mse  = mean_squared_error(y_test_qslice, q_preds)\n",
    "    q_rmse = np.sqrt(q_mse)\n",
    "    q_mae  = mean_absolute_error(y_test_qslice, q_preds)\n",
    "    q_r2   = r2_score(y_test_qslice, q_preds)\n",
    "\n",
    "    res_df = pd.concat([\n",
    "        res_df,\n",
    "        pd.DataFrame([[\"VQR (Quantum)\",\"Quantum\", q_mse, q_rmse, q_mae, q_r2, q_fit_time, q_pred_time]],\n",
    "                     columns=res_df.columns)\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    print(\"\\n=== Quantum Regression (VQR) Result ===\")\n",
    "    print(res_df[res_df[\"Model\"]==\"VQR (Quantum)\"].to_string(index=False))\n",
    "\n",
    "    # Show some quantum predictions vs actual\n",
    "    print(\"\\nSample predictions (Quantum VQR) vs actual (first 10 rows of its test slice):\")\n",
    "    for i in range(min(10, len(q_preds))):\n",
    "        print(f\"Pred: {q_preds[i]:6.2f} | Actual: {y_test_qslice[i]:6.2f}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n[Quantum block skipped] qiskit-machine-learning (VQR) not available:\", qml_import_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f5261",
   "metadata": {},
   "source": [
    "### 7. UNIFIED MODEL COMPARISON TABLE + QUICK RANKINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c652c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL COMPARISON (higher R² is better; lower RMSE/MAE is better) ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'res_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 9) UNIFIED MODEL COMPARISON TABLE + QUICK RANKINGS\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== FINAL COMPARISON (higher R² is better; lower RMSE/MAE is better) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m display(\u001b[43mres_df\u001b[49m.sort_values([\u001b[33m\"\u001b[39m\u001b[33mR2\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m\"\u001b[39m], ascending=[\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m]).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m      7\u001b[39m best_by_r2 = res_df.sort_values(\u001b[33m\"\u001b[39m\u001b[33mR2\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).iloc[\u001b[32m0\u001b[39m]\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest model by R²: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_by_r2[\u001b[33m'\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_by_r2[\u001b[33m'\u001b[39m\u001b[33mFamily\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mR²=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_by_r2[\u001b[33m'\u001b[39m\u001b[33mR2\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, RMSE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_by_r2[\u001b[33m'\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, MAE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_by_r2[\u001b[33m'\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'res_df' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 9) UNIFIED MODEL COMPARISON TABLE + QUICK RANKINGS\n",
    "# ============================================================\n",
    "print(\"\\n=== FINAL COMPARISON (higher R² is better; lower RMSE/MAE is better) ===\")\n",
    "display(res_df.sort_values([\"R2\",\"RMSE\"], ascending=[False, True]).reset_index(drop=True))\n",
    "\n",
    "best_by_r2 = res_df.sort_values(\"R2\", ascending=False).iloc[0]\n",
    "print(f\"\\nBest model by R²: {best_by_r2['Model']} ({best_by_r2['Family']})  \"\n",
    "      f\"R²={best_by_r2['R2']:.3f}, RMSE={best_by_r2['RMSE']:.2f}, MAE={best_by_r2['MAE']:.2f}\")\n",
    "\n",
    "# Optional: Visual check — Predicted vs Actual scatter for the two top models\n",
    "def scatter_pred_vs_actual(y_true, y_pred, title):\n",
    "    plt.figure(figsize=(5.5,5))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.6)\n",
    "    lims = [min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())]\n",
    "    plt.plot(lims, lims, '--')\n",
    "    plt.xlabel(\"Actual Life Expectancy\")\n",
    "    plt.ylabel(\"Predicted Life Expectancy\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# For the overall best classical model and the neural net:\n",
    "scatter_pred_vs_actual(y_test.values, pred_store[best_clf], f\"{best_clf} — Pred vs Actual\")\n",
    "scatter_pred_vs_actual(y_test.values, dl_preds, \"Neural Net (Keras) — Pred vs Actual\")\n",
    "\n",
    "# If Quantum ran, plot that too on its (smaller) test slice\n",
    "if qml_available:\n",
    "    scatter_pred_vs_actual(y_test_qslice, q_preds, \"Quantum VQR — Pred vs Actual (subset)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
